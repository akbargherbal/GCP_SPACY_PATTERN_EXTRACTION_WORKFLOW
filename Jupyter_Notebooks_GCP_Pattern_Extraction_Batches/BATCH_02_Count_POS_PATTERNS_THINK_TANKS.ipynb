{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/BATCH_02'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERB .*? NOUN Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_pos = set('ADJ ADP ADV AUX CONJ CCONJ DET INTJ NOUN NUM PART PRON PROPN PUNCT SCONJ SYM VERB X SPACE'.split())\n",
    "set_pos\n",
    "list_ignore = [i for i in list(set_pos) if i not in 'VERB NOUN'.split()]\n",
    "pat_verb_noun = [\n",
    "    {'POS':'VERB'},\n",
    "    {'POS': {'IN': list_ignore}, 'OP': '*'},\n",
    "    {'POS': 'NOUN'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_lemma_pattern(doc, pat_name='anything', pat_collection='list_of_dictionaries'):\n",
    "    '''\n",
    "    Given a spacy doc object; find the span according to the pattern given.\n",
    "    ''' \n",
    "    matcher =  Matcher(vocab = nlp.vocab)\n",
    "    matcher.add(f'{pat_name}', pat_collection)\n",
    "    \n",
    "    \n",
    "    doc_match = matcher(doc)\n",
    "    \n",
    "    \n",
    "    list_container = []\n",
    "    for match in doc_match:\n",
    "        start = match[1]\n",
    "        end = match[2]\n",
    "        result = doc[start:end]\n",
    "        result = [i.lemma_ for i in result] # new!\n",
    "        result = ' '.join(result)\n",
    "        list_container.append(result)\n",
    "\n",
    "    return list_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle_nlp(folder='Path_to_pkl_files', pos_pat = 'Spacy_Pos_Pattern', pat_name='anything', min_freq=7):\n",
    "    '''\n",
    "    Read pickled NLP files; and count the frequency of certain part-of-speech patter.\n",
    "    Must give folder name in the form of dir/; It must be a local directory!\n",
    "    Also give a valid spacy pos patter in this form: [{'POS':'VERB'}, {'POS': 'NOUN'}]\n",
    "    '''\n",
    "    \n",
    "    input_pickle = [i for i in os.listdir(f'{folder}') if i.endswith('pkl')]\n",
    "\n",
    "    pkl_paths = [f'./{folder}{i}' for i in os.listdir(f'{folder}') if i.endswith('pkl')]\n",
    "    input_nlp = list(zip(pkl_paths, input_pickle))\n",
    "    counter = 1\n",
    "    container = []\n",
    "    for i in input_nlp:\n",
    "        print(f'''Reading: {i[1]}\\t@{i[0]}\\t{counter} of {len(input_nlp)}\n",
    "        ''')\n",
    "        \n",
    "        df = pd.read_pickle(i[0])\n",
    "        df['PAT'] = df['NLP'].apply(lambda x: get_pos_lemma_pattern(x, pat_name, pat_collection=[pos_pat]))\n",
    "        df_result = list(chain(*list(df['PAT'])))\n",
    "        container.append(df_result)\n",
    "        print(f'''Finished: {i[1]}\\t@{i[0]}\\t{counter} of {len(input_nlp)}\n",
    "        ''')\n",
    "        print('-'*80)\n",
    "        counter += 1\n",
    "    container = list(chain(*container))\n",
    "    dict_result = Counter(container).most_common()\n",
    "    dict_result = dict(dict_result)\n",
    "    dict_result = {k:v for k,v in dict_result.items() if v>=min_freq}\n",
    "    df_result = pd.DataFrame(data={\n",
    "        'PAT_V_NAME': dict_result.keys(),\n",
    "        'FREQ': dict_result.values()\n",
    "    })\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter name of the file BATCH_02_VERB_NOUN_PAT_THINK_TANKS\n"
     ]
    }
   ],
   "source": [
    "file_result_name = input('Please enter name of the file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_02_VERB_NOUN_PAT_THINK_TANKS\n"
     ]
    }
   ],
   "source": [
    "print(file_result_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: NLP_THINK_TANKS_10K_df_18.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_18.pkl\t1 of 9\n",
      "        \n",
      "Finished: NLP_THINK_TANKS_10K_df_18.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_18.pkl\t1 of 9\n",
      "        \n",
      "--------------------------------------------------------------------------------\n",
      "Reading: NLP_THINK_TANKS_10K_df_16.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_16.pkl\t2 of 9\n",
      "        \n",
      "Finished: NLP_THINK_TANKS_10K_df_16.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_16.pkl\t2 of 9\n",
      "        \n",
      "--------------------------------------------------------------------------------\n",
      "Reading: NLP_THINK_TANKS_10K_df_12.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_12.pkl\t3 of 9\n",
      "        \n",
      "Finished: NLP_THINK_TANKS_10K_df_12.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_12.pkl\t3 of 9\n",
      "        \n",
      "--------------------------------------------------------------------------------\n",
      "Reading: NLP_THINK_TANKS_10K_df_11.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_11.pkl\t4 of 9\n",
      "        \n",
      "Finished: NLP_THINK_TANKS_10K_df_11.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_11.pkl\t4 of 9\n",
      "        \n",
      "--------------------------------------------------------------------------------\n",
      "Reading: NLP_THINK_TANKS_10K_df_13.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_13.pkl\t5 of 9\n",
      "        \n",
      "Finished: NLP_THINK_TANKS_10K_df_13.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_13.pkl\t5 of 9\n",
      "        \n",
      "--------------------------------------------------------------------------------\n",
      "Reading: NLP_THINK_TANKS_10K_df_10.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_10.pkl\t6 of 9\n",
      "        \n",
      "Finished: NLP_THINK_TANKS_10K_df_10.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_10.pkl\t6 of 9\n",
      "        \n",
      "--------------------------------------------------------------------------------\n",
      "Reading: NLP_THINK_TANKS_10K_df_15.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_15.pkl\t7 of 9\n",
      "        \n",
      "Finished: NLP_THINK_TANKS_10K_df_15.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_15.pkl\t7 of 9\n",
      "        \n",
      "--------------------------------------------------------------------------------\n",
      "Reading: NLP_THINK_TANKS_10K_df_14.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_14.pkl\t8 of 9\n",
      "        \n",
      "Finished: NLP_THINK_TANKS_10K_df_14.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_14.pkl\t8 of 9\n",
      "        \n",
      "--------------------------------------------------------------------------------\n",
      "Reading: NLP_THINK_TANKS_10K_df_17.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_17.pkl\t9 of 9\n",
      "        \n",
      "Finished: NLP_THINK_TANKS_10K_df_17.pkl\t@./NLP_RESULT/NLP_THINK_TANKS_10K_df_17.pkl\t9 of 9\n",
      "        \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df = read_pickle_nlp('NLP_RESULT/', pos_pat=pat_verb_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAT_V_NAME</th>\n",
       "      <th>FREQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be a lot</td>\n",
       "      <td>2842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>take place</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>have a lot</td>\n",
       "      <td>1337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>develop country</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>talk a little bit</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7855</th>\n",
       "      <td>support human right</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7856</th>\n",
       "      <td>make history</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7857</th>\n",
       "      <td>serve as deputy</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7858</th>\n",
       "      <td>have infection</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7859</th>\n",
       "      <td>be an initiative</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7860 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               PAT_V_NAME  FREQ\n",
       "0                be a lot  2842\n",
       "1              take place  1562\n",
       "2              have a lot  1337\n",
       "3         develop country   848\n",
       "4       talk a little bit   692\n",
       "...                   ...   ...\n",
       "7855  support human right     7\n",
       "7856         make history     7\n",
       "7857      serve as deputy     7\n",
       "7858       have infection     7\n",
       "7859     be an initiative     7\n",
       "\n",
       "[7860 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_02_VERB_NOUN_PAT_THINK_TANKS\n"
     ]
    }
   ],
   "source": [
    "print(file_result_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(f'{file_result_name}.pkl', protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
